{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b2626b",
   "metadata": {},
   "source": [
    "(1) 데이터를 8:2로 분할하고 선형회귀를 적용하시오. 결정계수와 rmse를 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9418ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taeeu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mglearn\n",
    "\n",
    "X, y=mglearn.datasets.load_extended_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9161d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6fb22b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00395381, 0.        , 0.21041056, ..., 0.97394771, 0.21731141,\n",
       "        0.04848746],\n",
       "       [0.00171339, 0.        , 0.37939883, ..., 0.90187249, 0.21357086,\n",
       "        0.05057534],\n",
       "       [0.00120232, 0.3       , 0.1638563 , ..., 0.97170935, 0.26248671,\n",
       "        0.07090523],\n",
       "       ...,\n",
       "       [0.00162594, 0.        , 0.35007331, ..., 0.98798327, 0.23505388,\n",
       "        0.05592233],\n",
       "       [0.0025059 , 0.        , 0.23643695, ..., 0.97913066, 0.46608557,\n",
       "        0.22186595],\n",
       "       [0.00149286, 0.        , 0.13159824, ..., 1.        , 0.35761589,\n",
       "        0.12788913]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee691bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정계수 0.615885858407892\n",
      "RMSE 5.592657237078517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred=lr.predict(X_test)\n",
    "\n",
    "print(\"결정계수\", lr.score(X_test, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9d7f0",
   "metadata": {},
   "source": [
    "(2) 데이터를 8:2로 분할하고 릿지회귀를 적용하시오. alpha값을 0부터 1까지 0.1단위로 모두 탐색해서 결정계수가 가장 높을 때의 알파를 찾고, 해당알파로 다시 모델을 학습해서 결정계수와 rmse를 계산하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26de9a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#warinng 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid={'alpha':[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "ridge=Ridge(normalize=True)\n",
    "ridge_grid=GridSearchCV(ridge, param_grid)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "ridge_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e1491",
   "metadata": {},
   "source": [
    "- 다시학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e552afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정계수 0.7356090234954484\n",
      "RMSE 4.6399293657141945\n"
     ]
    }
   ],
   "source": [
    "rg=Ridge(normalize=True, alpha=0.1)\n",
    "rg.fit(X_train, y_train)\n",
    "pred=rg.predict(X_test)\n",
    "\n",
    "print(\"결정계수\", rg.score(X_test, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87843593",
   "metadata": {},
   "source": [
    "결정계수값은 커지고 RMSE값은 줄어들음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3a224",
   "metadata": {},
   "source": [
    "(3) 데이터를 8:2로 분할하고 라쏘회귀를 적용하시오. alpha값을 0부터 1까지 0.1단위로 모두 탐색해서 결정계수가 가장 높을 때의 알파를 찾고, 해당 알파로 다시 모델을 학습해서 결정계수와 rmse를 계산하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fa9ed6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso=Lasso(normalize=True)\n",
    "param_grid={'alpha':[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lasso_grid=GridSearchCV(lasso, param_grid)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "lasso_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fb5c0",
   "metadata": {},
   "source": [
    "- 다시학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebcf3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정계수 0.6901880385280231\n",
      "RMSE 5.022698918446969\n"
     ]
    }
   ],
   "source": [
    "lasso=Lasso(normalize=True, alpha=0)\n",
    "lasso.fit(X_train, y_train)\n",
    "pred=lasso.predict(X_test)\n",
    "\n",
    "print(\"결정계수\", lasso.score(X_test, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612282c4",
   "metadata": {},
   "source": [
    "해당데이터에서는 릿지회귀가 더 예측력이 더 좋은 것을 확인할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
